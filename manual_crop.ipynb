{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import importlib\n",
    "from Functions.crop_utils import calculate_box, generate_cropping_mask, load_img, get_framed_polygon\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "thumbnail_folder = \"/Users/jeffrey/Aerial History Project/Stitching/thumbnails/Nigeria/NCAP_DOS_SHELL_BP\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the image_shapes df and convert filepaths\n",
    "shape_df = pd.read_csv(os.path.join(thumbnail_folder, \"image_shapes.csv\"))\n",
    "shape_df.file_path = [os.path.join(thumbnail_folder, os.path.splitext(os.path.basename(x))[0] + '.jpg') for x in shape_df.file_path]\n",
    "\n",
    "\n",
    "# Convert the string representation of the tuples into actual tuples\n",
    "shape_df['original_shape'] = shape_df['original_shape'].apply(literal_eval)\n",
    "shape_df['thumbnail_shape'] = shape_df['thumbnail_shape'].apply(literal_eval)\n",
    "\n",
    "# Compute width_scale and height_scale\n",
    "shape_df['width_scale'] = shape_df.apply(lambda row: row['thumbnail_shape'][0] / row['original_shape'][0], axis=1)\n",
    "shape_df['height_scale'] = shape_df.apply(lambda row: row['thumbnail_shape'][1] / row['original_shape'][1], axis=1)\n",
    "\n",
    "# shape_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_crops(cropping_parameters, n=20):\n",
    "\n",
    "    for i, row in shape_df.iterrows():\n",
    "        fp = row.file_path\n",
    "        print(fp)\n",
    "        img_array = load_img(fp)\n",
    "        b = calculate_box(img_array, threshold=20, starting_from=other_params['cropping_origin'], mode=other_params['cropping_mode'])\n",
    "        boundaries = (b[0], b[2], b[1], b[3])  # calculate_box returns in the wrong order\n",
    "\n",
    "        # Crop the image using NumPy slicing\n",
    "        img_cropped_array = img_array[boundaries[1]:boundaries[3], boundaries[0]:boundaries[2]]\n",
    "\n",
    "        # # Display the cropped image\n",
    "        # plt.imshow(img_cropped_array, cmap='gray')  # Adjust color map if needed\n",
    "        # plt.axis('off')  # Hide the axes\n",
    "        # plt.show()\n",
    "        # print(\"Cropped Image Size:\", img_cropped_array.shape)\n",
    "\n",
    "        # Generate mask with the same size as the cropped image\n",
    "        # scale down the cropping parameters\n",
    "        cropping_parameters_scaled = cropping_parameters.copy()\n",
    "        for x, scale in [('margin_left', 'width_scale'), ('margin_right', 'width_scale'), \n",
    "                ('margin_top', 'height_scale'), ('margin_bottom', 'height_scale')]:\n",
    "            cropping_parameters_scaled[x] = cropping_parameters_scaled[x] * row[scale]\n",
    "\n",
    "        polygon = get_framed_polygon(b, cropping_parameters_scaled)\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(img_array, cmap='gray')\n",
    "        x, y = polygon.exterior.xy\n",
    "        ax.plot(x, y, color='red')  # Polygon outline\n",
    "\n",
    "        plt.axis('off')  # Hide the axes\n",
    "        plt.show()\n",
    "        if i >= n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Universal parameters\n",
    "These parameters apply for every kind of frame:\n",
    "- margin_bottom: Bottom margin in hundreds of pixels\n",
    "- margin_left: Left margin in hundreds of pixels\n",
    "- margin_top: Top margin in hundreds of pixels\n",
    "- margin_right: Right margin in hundreds of pixels\n",
    "- number_r: Binary flag for if the frame number is bottom right (default 0)\n",
    "- number_ul: Binary flag for if the frame number is on upper left (default 0)\n",
    "- number_padding_x: Width of the number padding mask expressed as a fraction of the image width\n",
    "- number_padding_y: Height of the number padding mask expressed as a fraction of the image height\n",
    "\n",
    "\n",
    "## Frame specific parameters\n",
    "- corners\n",
    "    - corners_height: corner mask height expressed as a fraction of the image height\n",
    "    - corners_width: corner width expressed as a fraction of the image width\n",
    "\n",
    "- midpoints\n",
    "    - clip_long_side: length of the long side of the clip expressed as a fraction of the image side length\n",
    "    - clip_short_side: lenght of the short side of the clip expressed as a fraction of the image side length   \n",
    "- v-shape\n",
    "  v_height: height of the v-shape clip expressed as a fraction of the image height\n",
    "  v_width: width of the v-shape clip expressed as a fraction of the image width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropping_parameters = {\n",
    "    \"b_lg\": 1, \n",
    "    \"clip_long_side\": 0.04818053378598765, \n",
    "    \"clip_short_side\": 0.01, \n",
    "    \"corners\": 1, \n",
    "    \"corners_height\": 0.06207328840129208, \n",
    "    \"corners_width\": 0.08519120208022454, \n",
    "    \"l_lg\": 1, \n",
    "    \"margin_bottom\": 8, \n",
    "    \"margin_left\": 8, \n",
    "    \"margin_lg\": 2, \n",
    "    \"margin_right\": 8, \n",
    "    \"margin_top\": 4, \n",
    "    \"midpoints\": 0, \n",
    "    \"number_padding_x\": 0.1, \n",
    "    \"number_padding_y\": 0.07, \n",
    "    \"number_r\": 0, \n",
    "    \"number_ul\": 0, \n",
    "    \"r_lg\": 1, \n",
    "    \"t_lg\": 1, \n",
    "    \"v_shape\": 0\n",
    "    }\n",
    "\n",
    "other_params = {\n",
    "    'cropping_std_threshold': 20,\n",
    "    'cropping_filter_sigma': None,\n",
    "    'cropping_origin': 'side',\n",
    "    'cropping_mode': 'levels'\n",
    "}\n",
    "\n",
    "print(cropping_parameters)\n",
    "preview_crops(cropping_parameters, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stitch-service",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
